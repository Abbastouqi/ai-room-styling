{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üè† AI Room Redesign Studio - Google Colab\n",
        "\n",
        "Transform your room images and videos with AI-powered interior design!\n",
        "\n",
        "**Features:**\n",
        "- ‚ö° GPU-accelerated processing (<1 minute for images)\n",
        "- üé® Multiple styles: Modern, Luxury, Minimal, Custom\n",
        "- üñºÔ∏è Support for images and videos\n",
        "- üåê Web interface with real-time progress\n",
        "\n",
        "**Instructions:**\n",
        "1. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
        "2. Run all cells in order\n",
        "3. Upload your room image/video when prompted\n",
        "4. Get your redesigned room!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-header"
      },
      "source": [
        "## üöÄ Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check-gpu"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "import os\n",
        "\n",
        "print(\"üîç System Information:\")\n",
        "print(f\"Python version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected. Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
        "\n",
        "print(f\"\\nüíæ Disk space: {os.statvfs('/').f_bavail * os.statvfs('/').f_frsize / 1e9:.1f} GB available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone-repo"
      },
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/Abbastouqi/ai-room-styling.git\n",
        "%cd ai-room-styling\n",
        "\n",
        "print(\"‚úÖ Repository cloned successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-deps"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "\n",
        "# Install core ML libraries\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install diffusers transformers accelerate safetensors\n",
        "!pip install ultralytics opencv-python pillow numpy\n",
        "!pip install flask flask-cors werkzeug\n",
        "!pip install timm huggingface-hub\n",
        "\n",
        "# Install SAM\n",
        "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "\n",
        "print(\"‚úÖ Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download-models"
      },
      "outputs": [],
      "source": [
        "# Download required models\n",
        "print(\"üîΩ Downloading models...\")\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "# Create models directory\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Download SAM model\n",
        "sam_url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\"\n",
        "sam_path = \"models/sam_vit_b.pth\"\n",
        "\n",
        "if not os.path.exists(sam_path):\n",
        "    print(\"Downloading SAM model (375MB)...\")\n",
        "    urllib.request.urlretrieve(sam_url, sam_path)\n",
        "    print(\"‚úÖ SAM model downloaded\")\n",
        "else:\n",
        "    print(\"‚úÖ SAM model already exists\")\n",
        "\n",
        "# YOLOv8 will be downloaded automatically by ultralytics\n",
        "print(\"‚úÖ Models ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usage-header"
      },
      "source": [
        "## üé® Usage Methods\n",
        "\n",
        "Choose one of the methods below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "method1-header"
      },
      "source": [
        "### Method 1: üåê Web Interface (Recommended)\n",
        "\n",
        "Run the full web application with beautiful UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "web-interface"
      },
      "outputs": [],
      "source": [
        "# Method 1: Web Interface with ngrok\n",
        "!pip install pyngrok\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import time\n",
        "import sys\n",
        "sys.path.append('/content/ai-room-styling')\n",
        "\n",
        "# Set ngrok auth token (optional - get free token from ngrok.com)\n",
        "# ngrok.set_auth_token(\"your_token_here\")\n",
        "\n",
        "def start_backend():\n",
        "    \"\"\"Start Flask backend\"\"\"\n",
        "    os.chdir('/content/ai-room-styling/backend')\n",
        "    os.system('python app.py')\n",
        "\n",
        "# Start backend in background\n",
        "backend_thread = threading.Thread(target=start_backend, daemon=True)\n",
        "backend_thread.start()\n",
        "\n",
        "# Wait for backend to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Create ngrok tunnel\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"üåê Backend API: {public_url}\")\n",
        "\n",
        "# Serve frontend\n",
        "os.chdir('/content/ai-room-styling/frontend')\n",
        "frontend_url = ngrok.connect(8080)\n",
        "print(f\"üé® Frontend UI: {frontend_url}\")\n",
        "print(\"\\nüöÄ Click the Frontend UI link above to access the web interface!\")\n",
        "print(\"üìù Note: Update the API URL in script.js if needed\")\n",
        "\n",
        "# Start frontend server\n",
        "!python -m http.server 8080"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "method2-header"
      },
      "source": [
        "### Method 2: üì± Simple Upload Interface\n",
        "\n",
        "Upload files directly in Colab and process them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "simple-interface"
      },
      "outputs": [],
      "source": [
        "# Method 2: Simple Colab Interface\n",
        "import sys\n",
        "sys.path.append('/content/ai-room-styling')\n",
        "\n",
        "from google.colab import files\n",
        "import asyncio\n",
        "import os\n",
        "from pathlib import Path\n",
        "from IPython.display import Image, display, HTML\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image as PILImage\n",
        "import numpy as np\n",
        "\n",
        "# Import our optimized pipeline\n",
        "from src.optimized_pipeline import OptimizedPipeline, OptimizationConfig\n",
        "\n",
        "print(\"üé® AI Room Redesign - Simple Interface\")\n",
        "print(\"üìÅ Upload your room image or video below:\")\n",
        "\n",
        "# Upload files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Process uploaded files\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\nüìÇ Processing: {filename}\")\n",
        "    \n",
        "    # Save uploaded file\n",
        "    input_path = f\"/content/ai-room-styling/data/input/{filename}\"\n",
        "    os.makedirs(os.path.dirname(input_path), exist_ok=True)\n",
        "    \n",
        "    with open(input_path, 'wb') as f:\n",
        "        f.write(uploaded[filename])\n",
        "    \n",
        "    print(f\"‚úÖ Saved to: {input_path}\")\n",
        "    \n",
        "    # Show original image if it's an image\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        print(\"\\nüñºÔ∏è Original Image:\")\n",
        "        display(Image(input_path, width=400))\n",
        "\n",
        "print(\"\\n‚úÖ Upload complete! Run the next cell to process.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "process-files"
      },
      "outputs": [],
      "source": [
        "# Configure processing options\n",
        "print(\"‚öôÔ∏è Configuration:\")\n",
        "\n",
        "# Style selection\n",
        "style = \"modern\"  # Options: \"modern\", \"luxury\", \"minimal\", \"custom\"\n",
        "custom_prompt = None  # Set this if style=\"custom\"\n",
        "\n",
        "# If you want custom style, uncomment and modify:\n",
        "# style = \"custom\"\n",
        "# custom_prompt = \"Scandinavian living room with light wood furniture, white walls, cozy textiles\"\n",
        "\n",
        "print(f\"Style: {style}\")\n",
        "if custom_prompt:\n",
        "    print(f\"Custom prompt: {custom_prompt}\")\n",
        "\n",
        "# Initialize optimized pipeline\n",
        "config = OptimizationConfig(\n",
        "    use_gpu=torch.cuda.is_available(),\n",
        "    batch_size=4 if torch.cuda.is_available() else 2,\n",
        "    use_fp16=torch.cuda.is_available(),\n",
        "    cache_models=True,\n",
        "    parallel_stages=True,\n",
        "    memory_efficient=True\n",
        ")\n",
        "\n",
        "print(f\"\\nüöÄ Initializing pipeline (GPU: {config.use_gpu})...\")\n",
        "pipeline = OptimizedPipeline(config)\n",
        "\n",
        "# Get input files\n",
        "input_dir = Path(\"/content/ai-room-styling/data/input\")\n",
        "input_files = list(input_dir.glob(\"*\"))\n",
        "input_files = [f for f in input_files if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.mp4', '.avi', '.mov']]\n",
        "\n",
        "if not input_files:\n",
        "    print(\"‚ùå No input files found. Please upload files first.\")\n",
        "else:\n",
        "    print(f\"\\nüìÅ Found {len(input_files)} file(s) to process\")\n",
        "    \n",
        "    # Process files\n",
        "    print(\"\\nüé® Starting AI room redesign...\")\n",
        "    print(\"‚è±Ô∏è This may take 30-60 seconds with GPU, 5-10 minutes with CPU\")\n",
        "    \n",
        "    import time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Run the pipeline\n",
        "    results = await pipeline.process_batch(\n",
        "        input_paths=[str(f) for f in input_files],\n",
        "        style=style,\n",
        "        custom_prompt=custom_prompt\n",
        "    )\n",
        "    \n",
        "    processing_time = time.time() - start_time\n",
        "    \n",
        "    # Save results\n",
        "    output_dir = Path(\"/content/ai-room-styling/data/output\")\n",
        "    pipeline.save_results(results, output_dir)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Processing complete in {processing_time:.1f} seconds!\")\n",
        "    print(f\"üìÅ Results saved to: {output_dir}\")\n",
        "    \n",
        "    # Display results\n",
        "    print(\"\\nüé® Results:\")\n",
        "    \n",
        "    for result in results:\n",
        "        input_path = Path(result['input_path'])\n",
        "        output_files = list(output_dir.glob(f\"{input_path.stem}_redesigned.*\"))\n",
        "        \n",
        "        if output_files:\n",
        "            output_file = output_files[0]\n",
        "            \n",
        "            print(f\"\\nüì∏ {input_path.name} ‚Üí {output_file.name}\")\n",
        "            \n",
        "            # Show comparison for images\n",
        "            if input_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
        "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "                \n",
        "                # Original\n",
        "                original = PILImage.open(input_path)\n",
        "                ax1.imshow(original)\n",
        "                ax1.set_title(\"Original\")\n",
        "                ax1.axis('off')\n",
        "                \n",
        "                # Redesigned\n",
        "                if output_file.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
        "                    redesigned = PILImage.open(output_file)\n",
        "                    ax2.imshow(redesigned)\n",
        "                    ax2.set_title(f\"Redesigned ({style.title()})\")\n",
        "                    ax2.axis('off')\n",
        "                \n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "            \n",
        "            # Download link\n",
        "            print(f\"üíæ Download: {output_file}\")\n",
        "    \n",
        "    # Cleanup\n",
        "    pipeline.cleanup()\n",
        "    \n",
        "    print(\"\\nüéâ All done! You can download the results from the files panel.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "method3-header"
      },
      "source": [
        "### Method 3: üîó Direct API Usage\n",
        "\n",
        "Use the pipeline directly with Python code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "direct-api"
      },
      "outputs": [],
      "source": [
        "# Method 3: Direct API Usage\n",
        "import sys\n",
        "sys.path.append('/content/ai-room-styling')\n",
        "\n",
        "import asyncio\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from src.optimized_pipeline import OptimizedPipeline, OptimizationConfig\n",
        "\n",
        "# Example: Process a sample image\n",
        "async def process_sample():\n",
        "    # Configuration\n",
        "    config = OptimizationConfig(\n",
        "        use_gpu=torch.cuda.is_available(),\n",
        "        batch_size=4,\n",
        "        use_fp16=True,\n",
        "        cache_models=True\n",
        "    )\n",
        "    \n",
        "    # Initialize pipeline\n",
        "    pipeline = OptimizedPipeline(config)\n",
        "    \n",
        "    # You can replace this with your own image URL or upload\n",
        "    sample_image_url = \"https://images.unsplash.com/photo-1586023492125-27b2c045efd7?w=512&h=512&fit=crop\"\n",
        "    \n",
        "    # Download sample image\n",
        "    import urllib.request\n",
        "    os.makedirs('/content/sample_input', exist_ok=True)\n",
        "    sample_path = '/content/sample_input/room.jpg'\n",
        "    \n",
        "    print(\"üì• Downloading sample room image...\")\n",
        "    urllib.request.urlretrieve(sample_image_url, sample_path)\n",
        "    \n",
        "    # Process with different styles\n",
        "    styles = ['modern', 'luxury', 'minimal']\n",
        "    \n",
        "    for style in styles:\n",
        "        print(f\"\\nüé® Processing with {style} style...\")\n",
        "        \n",
        "        results = await pipeline.process_batch(\n",
        "            input_paths=[sample_path],\n",
        "            style=style\n",
        "        )\n",
        "        \n",
        "        # Save results\n",
        "        output_dir = Path(f'/content/output_{style}')\n",
        "        pipeline.save_results(results, output_dir)\n",
        "        \n",
        "        print(f\"‚úÖ {style.title()} style complete!\")\n",
        "    \n",
        "    # Cleanup\n",
        "    pipeline.cleanup()\n",
        "    \n",
        "    print(\"\\nüéâ All styles processed! Check the output folders.\")\n",
        "\n",
        "# Run the example\n",
        "await process_sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download-header"
      },
      "source": [
        "## üì• Download Results\n",
        "\n",
        "Download your processed images/videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download-results"
      },
      "outputs": [],
      "source": [
        "# Download all results\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "def create_results_zip():\n",
        "    \"\"\"Create a zip file with all results\"\"\"\n",
        "    zip_path = '/content/room_redesign_results.zip'\n",
        "    \n",
        "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "        # Add files from output directories\n",
        "        output_dirs = [\n",
        "            '/content/ai-room-styling/data/output',\n",
        "            '/content/output_modern',\n",
        "            '/content/output_luxury', \n",
        "            '/content/output_minimal'\n",
        "        ]\n",
        "        \n",
        "        for output_dir in output_dirs:\n",
        "            if os.path.exists(output_dir):\n",
        "                for root, dirs, files in os.walk(output_dir):\n",
        "                    for file in files:\n",
        "                        file_path = os.path.join(root, file)\n",
        "                        arcname = os.path.relpath(file_path, '/content')\n",
        "                        zipf.write(file_path, arcname)\n",
        "                        print(f\"Added: {arcname}\")\n",
        "    \n",
        "    return zip_path\n",
        "\n",
        "# Create and download zip\n",
        "if any(os.path.exists(d) for d in ['/content/ai-room-styling/data/output', '/content/output_modern']):\n",
        "    print(\"üì¶ Creating results archive...\")\n",
        "    zip_path = create_results_zip()\n",
        "    \n",
        "    print(f\"‚úÖ Results archived: {zip_path}\")\n",
        "    print(\"üíæ Downloading...\")\n",
        "    \n",
        "    files.download(zip_path)\n",
        "    print(\"üéâ Download complete!\")\n",
        "else:\n",
        "    print(\"‚ùå No results found. Please process some images first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tips-header"
      },
      "source": [
        "## üí° Tips & Troubleshooting\n",
        "\n",
        "### Performance Tips:\n",
        "- **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU (T4 recommended)\n",
        "- **Use smaller images**: 512x512 works best\n",
        "- **Close other tabs**: Free up GPU memory\n",
        "\n",
        "### Common Issues:\n",
        "- **Out of Memory**: Reduce batch_size in config\n",
        "- **Slow processing**: Make sure GPU is enabled\n",
        "- **Model download fails**: Check internet connection\n",
        "\n",
        "### Expected Processing Times:\n",
        "- **With GPU (T4)**: 30-60 seconds per image\n",
        "- **With CPU**: 5-10 minutes per image\n",
        "- **Videos**: 2-5 minutes with GPU, 1-3 hours with CPU\n",
        "\n",
        "### Supported Formats:\n",
        "- **Images**: JPG, PNG, JPEG\n",
        "- **Videos**: MP4, AVI, MOV\n",
        "- **Max size**: 100MB per file\n"
      ]
    }
  ]
}